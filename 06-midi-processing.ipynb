{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e173c011",
   "metadata": {},
   "source": [
    "## 6. Process MIDI data\n",
    "\n",
    "This notebook contains code for processing the downloaded MIDI in a number of ways. It isn't necessary to run, since the processed data is available to be downloaded HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd9b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "from music21 import converter, instrument, note\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from fractions import Fraction\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c220e9b",
   "metadata": {},
   "source": [
    "### Representations\n",
    "\n",
    "In my project, I explored a few different ways of representing the complex MIDI data. The first step for each of these is to convert the MIDI file into a numpy matrix with dimensions `(n_timesteps, 88)`, where each timestep represents 1/12 of a measure and 88 is the number of keys on the piano. For a given coordinate `(i, j)`, the value is 1 if the key is pressed and 0 otherwise.\n",
    "\n",
    "**Created in this notebook**\n",
    "- Raw text; `corpus-txt/`\n",
    "    - Remove duplicate timesteps (held chords)\n",
    "    - Convert each timestep to a string of \"on\" notes e.g. `\"C4,E4,G4,B4\"`\n",
    "    - Large vocabulary\n",
    "- Pairs; `corpus-pairs-txt/`\n",
    "    - Similar to raw text, except each chord is decomposed into the unique pairs of notes\n",
    "    - For example, the chord above gets converted into `\"C4,E4 C4,G4 C4,B4 E4,G4 E4,B4 G4,B4\"`\n",
    "    - The idea is that a chord is made up of the intervals within it\n",
    "    - Much smaller vocabulary\n",
    "\n",
    "**Created in notebook `08-make-cleaned-chord-dataset.ipynb`**\n",
    "- Chords; `chords-txt-cleaned/`\n",
    "    - Timesteps are filtered out if the notes present are not \"different enough\" from the previous timestep\n",
    "    - This is an attempt to reduce the number of timesteps to only include big chord changes instead of single notes being added or dropping out\n",
    "    - To reduce the vocabulary size, only the middle 3 octaves (36 keys v. 88 keys) are used\n",
    "- Chords augmented; `chords-txt-augmented/`\n",
    "    - Same as cleaned, except every original MIDI track is transposed to all 12 keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17da355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piano MIDI\n",
    "PIANO_MIDI_DIR = Path('piano-midi/')\n",
    "\n",
    "# For saving text representations of the midi\n",
    "TXT_FILEPATH = Path('corpus-txt/')\n",
    "TXT_FILEPATH.mkdir(exist_ok=True)\n",
    "\n",
    "# For saving text representations of note pairs within the midi\n",
    "TXT_PAIRS_FILEPATH = Path('corpus-pairs-txt/')\n",
    "TXT_PAIRS_FILEPATH.mkdir(exist_ok=True)\n",
    "\n",
    "# \n",
    "NP_FILEPATH = Path('midi-np/')\n",
    "NP_FILEPATH.mkdir(exist_ok=True)\n",
    "\n",
    "NP_CLEANED_FILEPATH = Path('midi-np-cleaned/')\n",
    "NP_CLEANED_FILEPATH.mkdir(exist_ok=True)\n",
    "\n",
    "NP_AUGMENTED_FILEPATH = Path('midi-np-augmented/')\n",
    "NP_AUGMENTED_FILEPATH.mkdir(exist_ok=True)\n",
    "\n",
    "MIDI_FILES = [PIANO_MIDI_DIR / file for file in os.listdir(PIANO_MIDI_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42f0de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompactNote():\n",
    "    # Mininal representation of a note\n",
    "    def __init__(self, pitch, offset, duration):\n",
    "        self.pitch = pitch\n",
    "        self.offset = offset\n",
    "        self.duration = duration\n",
    "        self.end = Fraction(self.offset) + Fraction(self.duration)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"<CompactNote @ {self.pitch} :: {self.offset} => {self.end} (duration: {self.duration})>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f21ab75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to estimate what key a track is in\n",
    "key_pattern = np.array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1]) / 7\n",
    "key_patterns = np.zeros((12, 12))\n",
    "for i in range(12):\n",
    "    key_patterns[i] = np.roll(key_pattern, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78482a4",
   "metadata": {},
   "source": [
    "### Utilities for MIDI processing\n",
    "\n",
    "The following is a lot of functions for processing MIDI, can be ignored for the purposes of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9b1e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_to_index = {\n",
    "    'C': 0,\n",
    "    'D': 2,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 7,\n",
    "    'A': 9,\n",
    "    'B': 11\n",
    "}\n",
    "\n",
    "index_to_step = ['C', 'D-', 'D', 'E-', 'E', 'F', 'G-', 'G', 'A-', 'A', 'B-', 'B']\n",
    "\n",
    "def lettername_to_base_index(lettername):\n",
    "    index = step_to_index[lettername[0]]\n",
    "    if len(lettername) > 1:\n",
    "        adjuster = 1 if lettername[1] == '#' else -1\n",
    "        index += adjuster * (len(lettername) - 1)\n",
    "    return index\n",
    "\n",
    "def pitch_str_to_pitch_index(pitch_str):\n",
    "    pitch, octave = pitch_str[:-1], int(pitch_str[-1])\n",
    "    pitch_index = lettername_to_base_index(pitch) + octave * 12 - 9\n",
    "    if pitch_index < 0 or pitch_index > 87:\n",
    "        return None\n",
    "    return pitch_index\n",
    "\n",
    "def pitch_index_to_pitch_str(pitch_index):\n",
    "    pitch_index += 9\n",
    "    return index_to_step[pitch_index % 12] + str(pitch_index // 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9efc85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_note(note_):\n",
    "    return CompactNote(\n",
    "        pitch=pitch_str_to_pitch_index(str(note_.pitch)),\n",
    "        offset=note_.offset,\n",
    "        duration=note_.quarterLength\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6f02edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_frequencies(arr):\n",
    "    arr_sum = np.sum(arr, axis=0)\n",
    "    note_sums = np.zeros(12)\n",
    "    for i in range(len(arr_sum)):\n",
    "        note_sums[(i - 3) % 12] += arr_sum[i]\n",
    "    note_frequencies = note_sums / np.sum(arr)\n",
    "    return note_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a146dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_key(arr):\n",
    "    note_frequencies = get_note_frequencies(arr)\n",
    "    best_dist = None\n",
    "    best_index = None\n",
    "    for i in range(12):\n",
    "        dist = np.linalg.norm(note_frequencies - key_patterns[i])\n",
    "        if not best_dist or dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_index = i\n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54c2639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center(arr):\n",
    "    arr_sum = np.sum(arr, axis=0)\n",
    "    center = np.average(np.arange(88), weights=arr_sum)\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca5c809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_to_key(arr, target_key):\n",
    "    key = estimate_key(arr)\n",
    "    target_key = 0\n",
    "    diff = (key - target_key) % 12\n",
    "    if diff == 0:\n",
    "        return arr\n",
    "    center = get_center(arr)\n",
    "    shift_down_amt = -diff\n",
    "    shift_up_amt = 12 - diff\n",
    "    shift_up_is_more_centered = abs((center + shift_up_amt) - 44) < abs((center + shift_down_amt) - 44)\n",
    "    shift_amt = shift_up_amt if shift_up_is_more_centered else shift_down_amt\n",
    "    buffer = np.zeros((len(arr), abs(shift_amt)))\n",
    "    if shift_amt > 0:\n",
    "        transposed = np.hstack((buffer, arr[:,:-shift_amt]))\n",
    "    else:\n",
    "        transposed = np.hstack((arr[:,-shift_amt:], buffer))\n",
    "    assert estimate_key(transposed) == 0\n",
    "    assert transposed.shape[1] == 88\n",
    "    return transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0da0186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_midi_to_compact_notes(midi_file):\n",
    "    score = converter.parse(midi_file).flatten()\n",
    "    all_notes = []\n",
    "    for element in score.notes:\n",
    "        if element.isNote:\n",
    "            all_notes.append(element)\n",
    "        else:\n",
    "            chord_notes = element.notes\n",
    "            for chord_note in chord_notes:\n",
    "                new_note = note.Note(str(chord_note.pitch), quarterLength=element.quarterLength)\n",
    "                new_note.offset = element.offset\n",
    "                all_notes.append(new_note)\n",
    "    compact_notes = []\n",
    "    for note_ in all_notes:\n",
    "        compact_note_ = compact_note(note_)\n",
    "        if compact_note_.pitch is not None:\n",
    "            compact_notes.append(compact_note_)\n",
    "    return compact_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf3a3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_of_notes_in_middle_registers(arr):\n",
    "    return np.sum(arr_c3_to_c6(arr)) / np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8459967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_c3_to_c6(arr):\n",
    "    return arr[:, 27:63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09470daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_compact_notes_to_array(compact_notes, resolution=12):\n",
    "    num_timesteps = max(compact_notes, key=lambda x: x.end).end * resolution\n",
    "    arr = np.zeros((int(num_timesteps), 88), dtype=np.uint8)\n",
    "    for note_ in compact_notes:\n",
    "        note_start, note_end = int(note_.offset * resolution), int(note_.end * resolution)\n",
    "        arr[note_start: note_end, note_.pitch] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2e0c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_midi_to_array(midi_file):\n",
    "    compact_notes = convert_midi_to_compact_notes(midi_file)\n",
    "    arr = convert_compact_notes_to_array(compact_notes)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31b17d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_array(arr, allow_empty=True):\n",
    "    new_arr = np.zeros(arr.shape, dtype=np.uint8)\n",
    "    i = 0\n",
    "    for j, timestep in enumerate(arr):\n",
    "        if j == 0 or not np.array_equal(timestep, arr[j-1]) and (allow_empty or np.any(timestep)):\n",
    "            new_arr[i] = timestep\n",
    "            i += 1\n",
    "    return new_arr[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b0c01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_txt(arr):\n",
    "    return ' '.join([''.join([str(x) for x in timestep]) for timestep in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "008af723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_chords(arr):\n",
    "    chords = []\n",
    "    for timestep in arr:\n",
    "        note_indices = np.where(timestep == 1)[0]\n",
    "        chords.append([pitch_index_to_pitch_str(x) for x in note_indices])\n",
    "    return chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72df293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_combinations(chord_notes):\n",
    "    if len(chord_notes) < 2:\n",
    "        return []\n",
    "    combinations = []\n",
    "    for i, note_a in enumerate(chord_notes[:-1]):\n",
    "        for j, note_b in enumerate(chord_notes[i+1:]):\n",
    "            combinations.append([note_a, note_b])\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44a796f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textify_chord_by_note_pairs(arr):\n",
    "    compressed_arr = compress_array(arr)\n",
    "    chords = arr_to_chords(compressed_arr)\n",
    "    all_pairs = [note_combinations(chord) for chord in chords]\n",
    "    txt = ''\n",
    "    for chord_pairs in all_pairs:\n",
    "        chord_pairs_txt = ' '.join([','.join([x for x in pair]) for pair in chord_pairs])\n",
    "        chord_pairs_txt = '<chord> ' + chord_pairs_txt + ' </chord>' if chord_pairs_txt else '<nochord>'\n",
    "        txt += ' ' + chord_pairs_txt\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    return txt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ac3eb",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce617f",
   "metadata": {},
   "source": [
    "Create raw `txt` files containing text representations of each non-repeated timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "45a02a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [12:52<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(MIDI_FILES):\n",
    "    # Convert file to array\n",
    "    arr = convert_midi_to_array(file)\n",
    "    # Remove duplicate timesteps\n",
    "    arr_compressed = compress_array(arr)\n",
    "    with open(TXT_FILEPATH / f\"{file.name[:-4]}.txt\", \"w\") as f:\n",
    "        f.write(arr_to_txt(arr_compressed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54752029",
   "metadata": {},
   "source": [
    "Create note pairs text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "1fde5677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [03:05<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(MIDI_FILES):\n",
    "    # Convert file to array\n",
    "    arr = convert_midi_to_array(file)\n",
    "    # Convert array to note pairs\n",
    "    text = textify_chord_by_note_pairs(arr)\n",
    "    with open(TXT_PAIRS_FILEPATH / f\"{file.name[:-4]}.txt\", \"w\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd409e",
   "metadata": {},
   "source": [
    "Save the raw, unprocessed numpy files converted from the midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ff660f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [03:42<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(MIDI_FILES):\n",
    "    arr = convert_midi_to_array(file)\n",
    "    np.save(NP_FILEPATH / f\"{file.name[:-4]}.npy\", arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d5f7e",
   "metadata": {},
   "source": [
    "Save the cleaned numpy files (transposed to the key of C, middle 3 octaves only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2989c3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [04:51<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(MIDI_FILES):\n",
    "    # Convert file to array\n",
    "    arr = convert_midi_to_array(file)\n",
    "    # Transpose to C\n",
    "    transposed = transpose_to_key(arr, target_key=0)\n",
    "    # Cut out low and high registers\n",
    "    cut = arr_c3_to_c6(transposed)\n",
    "    np.save(NP_CLEANED_FILEPATH / f\"{file.name[:-4]}.npy\", cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11417db3",
   "metadata": {},
   "source": [
    "Save the same cleaned numpy files, but transpose to all 12 keys to augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6ddfeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [15:21<00:00,  3.25s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(MIDI_FILES):\n",
    "    # Convert file to array\n",
    "    arr = convert_midi_to_array(file)\n",
    "    for i in range(12):\n",
    "        # Transpose to given key\n",
    "        transposed = transpose_to_key(arr, target_key=i)\n",
    "        cut = arr_c3_to_c6(transposed)\n",
    "        np.save(NP_AUGMENTED_FILEPATH / f\"{file.name[:-4]}_key{i}.npy\", cut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
