{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b958ba1",
   "metadata": {},
   "source": [
    "## 9. GPT for learning note pairs\n",
    "\n",
    "Now we apply Huggingface's GPT2 model to attempt to learn the chord representation using note pairs. Recall that the data format looks like `\"<chord> C4,E4 C4,G4 C4,B4 E4,G4 E4,B4 G4,B4 </chord>\"`, which in this case represents the chord consisting of the notes `C4, E4, G4, B4`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3447bf9",
   "metadata": {},
   "source": [
    "### Load necessary libraries and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa7e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2TokenizerFast, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80fd1292",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_SAVEDIR = Path('tokenizers/pair-tokenizer')\n",
    "LM_MODEL_SAVEDIR = Path('models/gpt-pairs/')\n",
    "LM_MODEL_SAVEDIR.mkdir(exist_ok=True, parents=True)\n",
    "TXT_LOCATION = Path('corpus-pairs-txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf98283",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(TOKENIZER_SAVEDIR, \n",
    "                                              bos_token=\"<start>\", \n",
    "                                              eos_token=\"</start>\",\n",
    "                                              unk_token=\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1897dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_head=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd10a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters: 88399104\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = GPT2LMHeadModel(config=config)\n",
    "print('Num parameters:', model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82dccf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chords(tokens, boc_token, eoc_token):\n",
    "    ''' Split tokens into lists of chords '''\n",
    "    sequences_joined = []\n",
    "    current = []\n",
    "    inChord = False\n",
    "    for token in tokens:\n",
    "        if token == boc_token:\n",
    "            inChord = True\n",
    "            current.append(token)\n",
    "        elif token == eoc_token:\n",
    "            current.append(token)\n",
    "            sequences_joined.append(current)\n",
    "            current = []\n",
    "            inChord = False\n",
    "        else:\n",
    "            if inChord:\n",
    "                current.append(token)\n",
    "            else:\n",
    "                sequences_joined.append([token])\n",
    "    return sequences_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5668d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    ''' Create a torch Dataset that tokenizes input examples and pads to max length\n",
    "        Takes care to not cut off in the middle of a chord'''\n",
    "    def __init__(self, src_files, tokenizer, num_chords):\n",
    "        self.max_len = 0\n",
    "        nc = num_chords\n",
    "        boc_token, eoc_token, self.pad_token = tokenizer.encode('<chord> </chord> <pad>')\n",
    "        self.examples = []\n",
    "        for src_file in tqdm(src_files):\n",
    "            words = src_file.read_text(encoding=\"utf-8\")\n",
    "            words = '<start> ' + words + ' </start>'\n",
    "            tokenized = tokenizer.encode(words)\n",
    "            chords = split_into_chords(tokenized, boc_token, eoc_token)\n",
    "            chunks = [torch.tensor(list(itertools.chain(*chords[i:i+nc]))) for i in range(0, len(chords) - nc + 1, nc // 2)]\n",
    "            for example in chunks:\n",
    "                self.examples.append(example)\n",
    "                self.max_len = max(self.max_len, len(example))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        tensor = torch.ones(self.max_len, dtype=torch.int64) * self.pad_token\n",
    "        example = self.examples[i]\n",
    "        tensor[:len(example)] = example\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b51ae2",
   "metadata": {},
   "source": [
    "Create dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae018e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [00:05<00:00, 55.63it/s]\n"
     ]
    }
   ],
   "source": [
    "src_files = list(Path(TXT_LOCATION).glob(\"**/*.txt\"))\n",
    "dataset = CustomDataset(src_files, tokenizer, num_chords=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c86f65",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d1ce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<chord> C3,C4 </chord> <chord> A-3,F4 </chord> <nochord> <chord> B-2,A-3 B-2,B-3 B-2,D-4 B-2,G-4 A-3,B-3 A-3,D-4 A-3,G-4 B-3,D-4 B-3,G-4 D-4,G-4 </chord> <nochord> <chord> A-3,D4 A-3,G-4 A-3,D-5 A-3,G-5 D4,G-4 D4,D-5 D4,G-5 G-4,D-5 G-4,G-5 D-5,G-5 </chord> <nochord> <chord> A-3,D4 A-3,G-4 A-3,B-4 A-3,D-5 A-3,G-5 D4,G-4 D4,B-4 D4,D-5 D4,G-5 G-4,B-4 G-4,D-5 G-4,G-5 B-4,D-5 B-4,G-5 D-5,G-5 </chord> <nochord> <chord> A-3,D4 A-3,G-4 A-3,B4 A-3,E-5 A-3,G-5 A-3,B5 D4,G-4 D4,B4 D4,E-5 D4,G-5 D4,B5 G-4,B4 G-4,E-5 G-4,G-5 G-4,B5 B4,E-5 B4,G-5 B4,B5 E-5,G-5 E-5,B5 G-5,B5 </chord> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset.__getitem__(104))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704cb8a",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now, we simply create a data collator, define the training arguments, train, and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b9a889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c549ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=LM_MODEL_SAVEDIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=10000,\n",
    "    logging_steps=2000,\n",
    "    save_total_limit=1,\n",
    "    prediction_loss_only=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
